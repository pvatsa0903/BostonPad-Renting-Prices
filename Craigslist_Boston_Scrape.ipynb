{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Craigslist_Boston_Scrape.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt9LRdJ8FV-2",
        "outputId": "c11db4b2-43fc-47d7-cd23-01ff5cc9ac61"
      },
      "source": [
        "#import get to call a get request on the site\n",
        "from requests import get\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "import re\n",
        "from random import randint #avoid throttling by not sending too many requests one after the other\n",
        "from warnings import warn\n",
        "from time import time\n",
        "from IPython.core.display import clear_output\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "zipcodes=[\"02128\", \"02115\", \"02130\", \"02129\", \"02119\", \"02114\", \"02113\", \"02109\", \"02108\", \"02110\", \n",
        "          \"02210\", \"02116\", \"02111\", \"02127\", \"02118\", \"02199\", \"02215\", \"02120\", \"02125\", \"02122\", \n",
        "          \"02124\", \"02131\", \"02121\", \"02126\", \"02136\", \"02132\", \"02135\", \"02467\", \"02026\", \n",
        "          \"02134\", \"02446\", \"02445\"]\n",
        "post_timing = []\n",
        "post_hoods = []\n",
        "post_title_texts = []\n",
        "bedroom_counts = []\n",
        "sqfts = []\n",
        "post_links = []\n",
        "post_prices = []\n",
        "zipcode =[]\n",
        "for i in range(0, len(zipcodes)):\n",
        "  #get the first page of the east bay housing prices\n",
        "  response = get('https://boston.craigslist.org/d/apartments-housing-for-rent/search/apa?postal='+zipcodes[i])\n",
        "  html_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "  #get the macro-container for the housing posts\n",
        "  posts = html_soup.find_all('li', class_= 'result-row')\n",
        "  #print(type(posts)) #to double check that I got a ResultSet\n",
        "  print(len(posts))\n",
        "\n",
        "  #find the total number of posts to find the limit of the pagination\n",
        "  results_num = html_soup.find('div', class_= 'search-legend')\n",
        "  results_total = int(results_num.find('span', class_='totalcount').text) #pulled the total count of posts as the upper bound of the pages array\n",
        "\n",
        "  #each page has 119 posts so each new page is defined as follows: s=120, s=240, s=360, and so on. So we need to step in size 120 in the np.arange function\n",
        "  pages = np.arange(0, results_total+1, 120)\n",
        "\n",
        "  iterations = 0\n",
        "  for page in pages:\n",
        "    #get request\n",
        "    response = get(\"https://boston.craigslist.org/d/apartments-housing-for-rent/search/apa?\" \n",
        "                   + \"s=\" #the parameter for defining the page number \n",
        "                   + str(page)\n",
        "                    + \"&postal=\"+zipcodes[i]) #the page number in the pages array from earlier\n",
        "                   #+ \"&hasPic=1\"\n",
        "                   #+ \"&availabilityMode=0\")\n",
        "\n",
        "    sleep(randint(1,5))\n",
        "     \n",
        "    #throw warning for status codes that are not 200\n",
        "    if response.status_code != 200:\n",
        "        warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
        "        \n",
        "    #define the html text\n",
        "    page_html = BeautifulSoup(response.text, 'html.parser')\n",
        "    \n",
        "    #define the posts\n",
        "    posts = html_soup.find_all('li', class_= 'result-row')\n",
        "        \n",
        "    #extract data item-wise\n",
        "    for post in posts:\n",
        "\n",
        "        if post.find('span', class_ = 'result-hood') is not None:\n",
        "\n",
        "            #posting date\n",
        "            #grab the datetime element 0 for date and 1 for time\n",
        "            zipcode.append(zipcodes[i])\n",
        "            post_datetime = post.find('time', class_= 'result-date')['datetime']\n",
        "            post_timing.append(post_datetime)\n",
        "\n",
        "            #neighborhoods\n",
        "            post_hood = post.find('span', class_= 'result-hood').text\n",
        "            post_hoods.append(post_hood)\n",
        "\n",
        "            #title text\n",
        "            post_title = post.find('a', class_='result-title hdrlnk')\n",
        "            post_title_text = post_title.text\n",
        "            post_title_texts.append(post_title_text)\n",
        "\n",
        "            #post link\n",
        "            post_link = post_title['href']\n",
        "            post_links.append(post_link)\n",
        "            \n",
        "            #removes the \\n whitespace from each side, removes the currency symbol, and turns it into an int\n",
        "            if len(post.a.text.strip())!=0:\n",
        "              post_price = post.a.text.strip().replace(\",\", \"\")\n",
        "              post_price = int(post_price.replace(\"$\", \"\"))\n",
        "            else: \n",
        "              post_price=0\n",
        "            post_prices.append(post_price)\n",
        "            \n",
        "            if post.find('span', class_ = 'housing') is not None:\n",
        "                \n",
        "                #if the first element is accidentally square footage\n",
        "                if 'ft2' in post.find('span', class_ = 'housing').text.split()[0]:\n",
        "                    \n",
        "                    #make bedroom nan\n",
        "                    bedroom_count = np.nan\n",
        "                    bedroom_counts.append(bedroom_count)\n",
        "                    \n",
        "                    #make sqft the first element\n",
        "                    sqft = int(post.find('span', class_ = 'housing').text.split()[0][:-3])\n",
        "                    sqfts.append(sqft)\n",
        "                    \n",
        "                #if the length of the housing details element is more than 2\n",
        "                elif len(post.find('span', class_ = 'housing').text.split()) > 2:\n",
        "                    \n",
        "                    #therefore element 0 will be bedroom count\n",
        "                    bedroom_count = post.find('span', class_ = 'housing').text.replace(\"br\", \"\").split()[0]\n",
        "                    bedroom_counts.append(bedroom_count)\n",
        "                    \n",
        "                    #and sqft will be number 3, so set these here and append\n",
        "                    sqft = int(post.find('span', class_ = 'housing').text.split()[2][:-3])\n",
        "                    sqfts.append(sqft)\n",
        "                    \n",
        "                #if there is num bedrooms but no sqft\n",
        "                elif len(post.find('span', class_ = 'housing').text.split()) == 2:\n",
        "                    \n",
        "                    #therefore element 0 will be bedroom count\n",
        "                    bedroom_count = post.find('span', class_ = 'housing').text.replace(\"br\", \"\").split()[0]\n",
        "                    bedroom_counts.append(bedroom_count)\n",
        "                    \n",
        "                    #and sqft will be number 3, so set these here and append\n",
        "                    sqft = np.nan\n",
        "                    sqfts.append(sqft)                    \n",
        "                \n",
        "                else:\n",
        "                    bedroom_count = np.nan\n",
        "                    bedroom_counts.append(bedroom_count)\n",
        "                \n",
        "                    sqft = np.nan\n",
        "                    sqfts.append(sqft)\n",
        "                \n",
        "            #if none of those conditions catch, make bedroom nan, this won't be needed    \n",
        "            else:\n",
        "                bedroom_count = np.nan\n",
        "                bedroom_counts.append(bedroom_count)\n",
        "                \n",
        "                sqft = np.nan\n",
        "                sqfts.append(sqft)\n",
        "            #   bedroom_counts.append(bedroom_count)\n",
        "                \n",
        "            #   sqft = np.nan\n",
        "            #   sqfts.append(sqft)\n",
        "                \n",
        "    iterations += 1\n",
        "    print(\"Page \" + str(iterations) + \" scraped successfully!\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Scrape complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n",
            "Page 1 scraped successfully!\n",
            "83\n",
            "Page 1 scraped successfully!\n",
            "120\n",
            "Page 1 scraped successfully!\n",
            "Page 2 scraped successfully!\n",
            "28\n",
            "Page 1 scraped successfully!\n",
            "38\n",
            "Page 1 scraped successfully!\n",
            "46\n",
            "Page 1 scraped successfully!\n",
            "57\n",
            "Page 1 scraped successfully!\n",
            "15\n",
            "Page 1 scraped successfully!\n",
            "9\n",
            "Page 1 scraped successfully!\n",
            "9\n",
            "Page 1 scraped successfully!\n",
            "46\n",
            "Page 1 scraped successfully!\n",
            "47\n",
            "Page 1 scraped successfully!\n",
            "41\n",
            "Page 1 scraped successfully!\n",
            "67\n",
            "Page 1 scraped successfully!\n",
            "50\n",
            "Page 1 scraped successfully!\n",
            "41\n",
            "Page 1 scraped successfully!\n",
            "90\n",
            "Page 1 scraped successfully!\n",
            "36\n",
            "Page 1 scraped successfully!\n",
            "58\n",
            "Page 1 scraped successfully!\n",
            "45\n",
            "Page 1 scraped successfully!\n",
            "66\n",
            "Page 1 scraped successfully!\n",
            "30\n",
            "Page 1 scraped successfully!\n",
            "25\n",
            "Page 1 scraped successfully!\n",
            "5\n",
            "Page 1 scraped successfully!\n",
            "12\n",
            "Page 1 scraped successfully!\n",
            "11\n",
            "Page 1 scraped successfully!\n",
            "120\n",
            "Page 1 scraped successfully!\n",
            "Page 2 scraped successfully!\n",
            "11\n",
            "Page 1 scraped successfully!\n",
            "5\n",
            "Page 1 scraped successfully!\n",
            "120\n",
            "Page 1 scraped successfully!\n",
            "Page 2 scraped successfully!\n",
            "88\n",
            "Page 1 scraped successfully!\n",
            "25\n",
            "Page 1 scraped successfully!\n",
            "\n",
            "\n",
            "Scrape complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfV1HZNlHNaE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "5b0367f5-dd7a-45ca-df58-53d999ccc43e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "eb_apts = pd.DataFrame({'posted': post_timing,\n",
        "                       'neighborhood': post_hoods,\n",
        "                       'post title': post_title_texts,\n",
        "                       'number bedrooms': bedroom_counts,\n",
        "                        'sqft': sqfts,\n",
        "                        'URL': post_links,\n",
        "                       'price': post_prices,\n",
        "                        'Zipcode': zipcode})\n",
        "print(eb_apts.info())\n",
        "eb_apts.head(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1681 entries, 0 to 1680\n",
            "Data columns (total 8 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   posted           1681 non-null   object \n",
            " 1   neighborhood     1681 non-null   object \n",
            " 2   post title       1681 non-null   object \n",
            " 3   number bedrooms  1491 non-null   object \n",
            " 4   sqft             764 non-null    float64\n",
            " 5   URL              1681 non-null   object \n",
            " 6   price            1681 non-null   int64  \n",
            " 7   Zipcode          1681 non-null   object \n",
            "dtypes: float64(1), int64(1), object(6)\n",
            "memory usage: 105.2+ KB\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posted</th>\n",
              "      <th>neighborhood</th>\n",
              "      <th>post title</th>\n",
              "      <th>number bedrooms</th>\n",
              "      <th>sqft</th>\n",
              "      <th>URL</th>\n",
              "      <th>price</th>\n",
              "      <th>Zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-12-06 08:45</td>\n",
              "      <td>(East Boston boston/cambridge/brookline )</td>\n",
              "      <td>1 MONTH FREE RENT. Available NOW. Edison Lofts...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://boston.craigslist.org/gbs/apa/d/boston...</td>\n",
              "      <td>2030</td>\n",
              "      <td>02128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-12-05 21:30</td>\n",
              "      <td>( boston/cambridge/brookline )</td>\n",
              "      <td>Secure bike parking, Poolside restaurant servi...</td>\n",
              "      <td>1</td>\n",
              "      <td>687.0</td>\n",
              "      <td>https://boston.craigslist.org/gbs/apa/d/boston...</td>\n",
              "      <td>3600</td>\n",
              "      <td>02128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-12-05 21:28</td>\n",
              "      <td>( boston/cambridge/brookline )</td>\n",
              "      <td>Access to boat landing, Music room, Energy Sta...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>478.0</td>\n",
              "      <td>https://boston.craigslist.org/gbs/apa/d/boston...</td>\n",
              "      <td>2850</td>\n",
              "      <td>02128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-12-05 21:26</td>\n",
              "      <td>( boston/cambridge/brookline )</td>\n",
              "      <td>Rooftop deck with seating and 270° views, Pet-...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>396.0</td>\n",
              "      <td>https://boston.craigslist.org/gbs/apa/d/boston...</td>\n",
              "      <td>2525</td>\n",
              "      <td>02128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-12-05 21:24</td>\n",
              "      <td>( boston/cambridge/brookline )</td>\n",
              "      <td>Low-flow fixtures, Nest Learning Thermostats™,...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>476.0</td>\n",
              "      <td>https://boston.craigslist.org/gbs/apa/d/boston...</td>\n",
              "      <td>2650</td>\n",
              "      <td>02128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-12-05 20:30</td>\n",
              "      <td>( boston/cambridge/brookline )</td>\n",
              "      <td>Access to a new waterfront park, Lounge with a...</td>\n",
              "      <td>1</td>\n",
              "      <td>567.0</td>\n",
              "      <td>https://boston.craigslist.org/gbs/apa/d/boston...</td>\n",
              "      <td>2700</td>\n",
              "      <td>02128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2021-12-04 12:36</td>\n",
              "      <td>(East Boston boston/cambridge/brookline )</td>\n",
              "      <td>Clean 1br ~ Parking ~ Public transit ~ Laundry</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://boston.craigslist.org/gbs/apa/d/east-b...</td>\n",
              "      <td>1600</td>\n",
              "      <td>02128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2021-12-02 13:35</td>\n",
              "      <td>(East Boston boston/cambridge/brookline )</td>\n",
              "      <td>FREE JANUARY RENT! Brand New Construction! No ...</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://boston.craigslist.org/gbs/apa/d/east-b...</td>\n",
              "      <td>3450</td>\n",
              "      <td>02128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2021-12-02 11:52</td>\n",
              "      <td>(Orient Heights, Top of the Hill, Madonna Are...</td>\n",
              "      <td>$1750 1BR East Boston, Orient Heights, Madonna...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://boston.craigslist.org/gbs/apa/d/east-b...</td>\n",
              "      <td>1750</td>\n",
              "      <td>02128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2021-12-01 18:22</td>\n",
              "      <td>( boston/cambridge/brookline )</td>\n",
              "      <td>Rooftop deck with seating and 270° views, Sun ...</td>\n",
              "      <td>2</td>\n",
              "      <td>917.0</td>\n",
              "      <td>https://boston.craigslist.org/gbs/apa/d/boston...</td>\n",
              "      <td>4150</td>\n",
              "      <td>02128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             posted  ... Zipcode\n",
              "0  2021-12-06 08:45  ...   02128\n",
              "1  2021-12-05 21:30  ...   02128\n",
              "2  2021-12-05 21:28  ...   02128\n",
              "3  2021-12-05 21:26  ...   02128\n",
              "4  2021-12-05 21:24  ...   02128\n",
              "5  2021-12-05 20:30  ...   02128\n",
              "6  2021-12-04 12:36  ...   02128\n",
              "7  2021-12-02 13:35  ...   02128\n",
              "8  2021-12-02 11:52  ...   02128\n",
              "9  2021-12-01 18:22  ...   02128\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEKxa4v1kGkx",
        "outputId": "7334bca0-448b-408a-cf48-36070a95eaa3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#drive.flush_and_unmount()\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks\"\n",
        "\n",
        "eb_apts.to_csv('Boston_Craigslist_all_zips.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL9ISWXknSA6"
      },
      "source": [
        "import pandas as pd\n",
        "eb_apts['Zipcode'] = pd.to_numeric(eb_apts['Zipcode'])\n",
        "eb_apts['number bedrooms'] = pd.to_numeric(eb_apts['number bedrooms'])\n",
        "eb_apts['Price per bedroom'] = eb_apts['price']/eb_apts['number bedrooms']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2TzvrEEm-09"
      },
      "source": [
        "univ_codes = [2115, 2215, 2116, 2108, 2125]\n",
        "eb_apts['LOCATION_TYPE'] = eb_apts['Zipcode'].apply(lambda x: 'University' if x in univ_codes else 'Non-university')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKKErc71mYYJ",
        "outputId": "5d2e9f2e-b67f-48e2-e77c-12c8e027d0d5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "Univ_values = eb_apts[eb_apts['LOCATION_TYPE']=='University']['price']\n",
        "Non_univ_values = eb_apts[eb_apts['LOCATION_TYPE']=='Non-university']['price']\n",
        "\n",
        "Univ_mean = np.mean(Univ_values)\n",
        "Non_univ_mean = np.mean(Non_univ_values)\n",
        "print(\"Univ mean value:\",Univ_mean)\n",
        "print(\"Non-Univ mean value:\",Non_univ_mean)\n",
        "Univ_std = np.std(Univ_values)\n",
        "Non_univ_std = np.std(Non_univ_values)\n",
        "print(\"Univ std value:\",Univ_std)\n",
        "print(\"Non-univ std value:\",Non_univ_std)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Univ mean value: 2907.010752688172\n",
            "Non-Univ mean value: 2782.698288159772\n",
            "Univ std value: 1200.5916327800985\n",
            "Non-univ std value: 1209.5391947964536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewWviPw5n-yv",
        "outputId": "6df71788-a04f-4e08-b321-94a9008b9bfc"
      },
      "source": [
        "from scipy.stats import ttest_ind\n",
        "ttest,pval1 = ttest_ind(Univ_values,Non_univ_values)\n",
        "print(\"t statistic\",ttest)\n",
        "print(\"p-value\",float(pval1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t statistic 1.5687739572003871\n",
            "p-value 0.11688904727340975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UNf0v-iozoF",
        "outputId": "98d52988-edf5-4bde-ce08-4ad63cc5821c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "Univ_values = eb_apts[eb_apts['LOCATION_TYPE']=='University']['Price per bedroom'].dropna()\n",
        "Non_univ_values = eb_apts[eb_apts['LOCATION_TYPE']=='Non-university']['Price per bedroom'].dropna()\n",
        "\n",
        "Univ_mean = np.mean(Univ_values)\n",
        "Non_univ_mean = np.mean(Non_univ_values)\n",
        "print(\"Univ mean value:\",Univ_mean)\n",
        "print(\"Non-Univ mean value:\",Non_univ_mean)\n",
        "Univ_std = np.std(Univ_values)\n",
        "Non_univ_std = np.std(Non_univ_values)\n",
        "print(\"Univ std value:\",Univ_std)\n",
        "print(\"Non-univ std value:\",Non_univ_std)\n",
        "from scipy.stats import ttest_ind\n",
        "ttest,pval1 = ttest_ind(Univ_values,Non_univ_values)\n",
        "print(\"t statistic\",ttest)\n",
        "print(\"p-value\",float(pval1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Univ mean value: 2101.2385290148445\n",
            "Non-Univ mean value: 1606.3566356606943\n",
            "Univ std value: 1190.2403952690127\n",
            "Non-univ std value: 839.2270218522004\n",
            "t statistic 7.829088021746101\n",
            "p-value 9.264200284352637e-15\n"
          ]
        }
      ]
    }
  ]
}